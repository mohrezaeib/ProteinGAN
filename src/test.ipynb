{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_dataframe_list_to_rows(df, target_column, separator):\n",
    "    \"\"\"Splits column that contains list into row per element of the list.\n",
    "\n",
    "    Args:\n",
    "      df: dataframe to split\n",
    "      target_column: the column containing the values to split\n",
    "      separator: the symbol used to perform the split\n",
    "\n",
    "    Returns:\n",
    "      dataframe with each entry for the target column separated,\n",
    "      with each element moved into a new row.  The values in the\n",
    "      other columns are duplicated across the newly divided rows.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def split_list_to_rows(row, row_accumulator, target_column, separator):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "          row: \n",
    "          row_accumulator: \n",
    "          target_column: \n",
    "          separator: \n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        split_row = row[target_column].split(separator)\n",
    "        for s in split_row:\n",
    "            new_row = row.to_dict()\n",
    "            new_row[target_column] = s\n",
    "            row_accumulator.append(new_row)\n",
    "\n",
    "    new_rows = []\n",
    "    df.apply(split_list_to_rows, axis=1, args=(new_rows, target_column, separator))\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def get_id_character_mapping(data, columns):\n",
    "    \"\"\"Creating a mapping between characters and ids given dataframe.\n",
    "\n",
    "    Args:\n",
    "      data: dataframe that contains characters that need to be converted to ids\n",
    "      column: a column of the dataframe that contains characters that need to be converted to ids\n",
    "      columns: \n",
    "\n",
    "    Returns:\n",
    "      id_to_character: dictionary of ids and characters\n",
    "      character_to_id: dictionary of characters and ids\n",
    "\n",
    "    \"\"\"\n",
    "    characters = set([])\n",
    "    for column in columns:\n",
    "        [characters.update(set(val)) for index, val in data[column].iteritems()]\n",
    "    characters = list(sorted(characters))\n",
    "\n",
    "    id_to_character = {i: characters[i] for i in range(len(characters))}\n",
    "    character_to_id = {characters[i]: i for i in range(len(characters))}\n",
    "    return id_to_character, character_to_id\n",
    "\n",
    "\n",
    "def get_category_to_id_mapping(data, column):\n",
    "    \"\"\"Creates two mappings for id and categorical value and vice verse for given column.\n",
    "    Id is a unique identifier of categorical value. Starting from 0.\n",
    "\n",
    "    Args:\n",
    "      data: dataframe that contains categorical values\n",
    "      column: a column of dataframe that contains categorical values for which a mapping from categorical value\n",
    "    to id is needed\n",
    "\n",
    "    Returns:\n",
    "      id_to_category: dictionary of ids and categories\n",
    "      category_to_id: dictionary of categories and ids\n",
    "\n",
    "    \"\"\"\n",
    "    categories = sorted(data[column].unique())\n",
    "    print(\"There are {} unique categories\".format(len(categories)))\n",
    "    id_to_category = {i: categories[i] for i in range(len(categories))}\n",
    "    category_to_id = {categories[i]: i for i in range(len(categories))}\n",
    "    return id_to_category, category_to_id\n",
    "\n",
    "\n",
    "\n",
    "def to_int_feature(data):\n",
    "    \"\"\"\n",
    "    Converts int list to tf Feature\n",
    "    Args:\n",
    "        data: int list to be stored in tf record\n",
    "\n",
    "    Returns:\n",
    "        tf Feature that is used in building tfrecord\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=data))\n",
    "\n",
    "\n",
    "def to_float_feature(data):\n",
    "    \"\"\"\n",
    "    Converts float list to tf Feature\n",
    "    Args:\n",
    "        data: float list to be stored in tf record\n",
    "\n",
    "    Returns:\n",
    "        tf Feature that is used in building tfrecord\n",
    "    \"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_as_npy(path, original_data, columns=[\"Label\", \"sequence\"], ):\n",
    "    \"\"\"Processes a dataframe and stores data into npy file\n",
    "\n",
    "    Args:\n",
    "      filename: the absolute path of the npy file where data should be stored\n",
    "      data: dataframe containing data to be stored\n",
    "      columns: list of columns that should be stored\n",
    "      extension: file extension\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    try:\n",
    "        filename = os.path.join(path, \"data.npy\")\n",
    "        np.save(filename, original_data[columns].values)\n",
    "\n",
    "        print(\"Data was stored in {}\".format(filename))\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong went writting in to npy file ({})\".format(filename))\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "from common.bio.sequence import Sequence\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from common.bio.constants import ID_TO_AMINO_ACID, AMINO_ACID_TO_ID, NON_STANDARD_AMINO_ACIDS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fasta_to_numpy(path, length):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        path: of the fasta file\n",
    "        separator: used in title of fasta file entry\n",
    "\n",
    "    Returns: numpy array of sequences\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path) as fasta_file:\n",
    "        sequences = []\n",
    "        for title, sequence in SimpleFastaParser(fasta_file):\n",
    "            sequence = sequence[:length]\n",
    "            to_pad = length - len(sequence)\n",
    "            sequence = sequence.rjust(len(sequence) - (to_pad // 2), '0')\n",
    "            sequence = sequence.ljust(length, '0')\n",
    "            if len(sequence) < length:\n",
    "                print(sequence.rjust(to_pad // 2, '0'))\n",
    "                print(to_pad, to_pad//2, length-len(sequence))\n",
    "            np_seq = np.asarray([AMINO_ACID_TO_ID[a] for a in sequence])\n",
    "            sequences.append(np_seq)\n",
    "        return np.stack(sequences, axis= 0)\n",
    "\n",
    "def from_amino_acid_to_id(data, column):\n",
    "    \"\"\"Converts sequences from amino acid to ids\n",
    "\n",
    "    Args:\n",
    "      data: data that contains amino acid that need to be converted to ids\n",
    "      column: a column of the dataframe that contains amino acid that need to be converted to ids\n",
    "\n",
    "    Returns:\n",
    "      array of ids\n",
    "\n",
    "    \"\"\"\n",
    "    return data[column].apply(lambda x: [AMINO_ACID_TO_ID[c] for c in x])\n",
    "\n",
    "\n",
    "def from_id_from_amino_acid(data, column):\n",
    "    \"\"\"Converts sequences from ids to amino acid characters\n",
    "\n",
    "    Args:\n",
    "      data: data that contains ids that need to be converted to amino acid\n",
    "      column: a column of the dataframe that contains ids that need to be converted to amino acid\n",
    "\n",
    "    Returns:\n",
    "      array of amino acid\n",
    "\n",
    "    \"\"\"\n",
    "    return [[ID_TO_AMINO_ACID[id] for id in val] for index, val in data[column].iteritems()]\n",
    "\n",
    "\n",
    "def filter_non_standard_amino_acids(data, column):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      data: dataframe containing amino acid sequence\n",
    "      column: a column of dataframe that contains amino acid sequence\n",
    "\n",
    "    Returns:\n",
    "      filtered data drame\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    data = data[~data[column].str.contains(\"|\".join(NON_STANDARD_AMINO_ACIDS))]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_protein_sequences(sequences, labels=None, d_scores=None):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      sequences: Protein sequences\n",
    "      id_to_enzyme_class: a dictionary to get enzyme class from its id\n",
    "      labels: Ids  of Enzyme classes (Default value = None)\n",
    "\n",
    "    Returns:\n",
    "      array of Sequence objects\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    for index, seq in enumerate(sequences):\n",
    "        label = None if labels is None else labels[index]\n",
    "        d_score = None if d_scores is None else d_scores[index]\n",
    "        seqs.append(Sequence(index, seq, label=label, d_score=d_score))\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def numpy_seqs_to_fasta(sequences, id_to_enzyme_class, labels=None, d_scores=None, strip_zeros=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      sequences: Protein sequences\n",
    "      id_to_enzyme_class: a dictionary to get enzyme class from its id\n",
    "      labels: Ids  of Enzyme classes (Default value = None)\n",
    "      d_scores: Values of discriminator (Default value = None)\n",
    "      strip_zeros: Flag to determine if special characters needs to be escape. Applicable for text in tersorboard\n",
    "    Returns:\n",
    "      array of strings with sequences and additional information\n",
    "\n",
    "    \"\"\"\n",
    "    seqs = get_protein_sequences(sequences, labels, d_scores)\n",
    "    return sequences_to_fasta(seqs, id_to_enzyme_class, True, strip_zeros)\n",
    "\n",
    "\n",
    "def sequences_to_fasta(sequences, id_to_enzyme_class, escape=True, strip_zeros=False):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      sequences: a list of Sequences object\n",
    "      id_to_enzyme_class: a dictionary to get enzyme class from its id\n",
    "      labels: Ids  of Enzyme classes (Default value = None)\n",
    "      escape: a flag to determine if special characters needs to be escape. Applicable for text in tersorboard\n",
    "      strip_zeros: a flag that determines whether zeros are removed from sequences\n",
    "    Returns:\n",
    "      string with sequences and additional information that mimics fasta format\n",
    "\n",
    "    \"\"\"\n",
    "    return os.linesep.join([seq.get_seq_in_fasta(id_to_enzyme_class, escape, strip_zeros) for seq in sequences])\n",
    "\n",
    "\n",
    "def print_protein_seq(sequences, id_to_enzyme_class, labels=None, d_scores=None):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "      sequences: Protein sequences\n",
    "      id_to_enzyme_class: a dictionary to get enzyme class from its id\n",
    "      labels: Ids  of Enzyme classes (Default value = None)\n",
    "      d_scores: Values of discriminator (Default value = None)\n",
    "\n",
    "    Returns:\n",
    "      Signal for DONE\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"\\n\".join(numpy_seqs_to_fasta(sequences, id_to_enzyme_class, labels, d_scores)))\n",
    "    return \"DONE\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fasta_to_numpy(path, length):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        path: of the fasta file\n",
    "        separator: used in title of fasta file entry\n",
    "\n",
    "    Returns: numpy array of sequences\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path) as fasta_file:\n",
    "        sequences = []\n",
    "        for title, sequence in SimpleFastaParser(fasta_file):\n",
    "            sequence = sequence[:length]\n",
    "            to_pad = length - len(sequence)\n",
    "            sequence = sequence.rjust(len(sequence) - (to_pad // 2), '0')\n",
    "            sequence = sequence.ljust(length, '0')\n",
    "            if len(sequence) < length:\n",
    "                print(sequence.rjust(to_pad // 2, '0'))\n",
    "                print(to_pad, to_pad//2, length-len(sequence))\n",
    "            np_seq = np.asarray([AMINO_ACID_TO_ID[a] for a in sequence])\n",
    "            sequences.append(np_seq)\n",
    "        return np.stack(sequences, axis= 0)\n",
    "\n",
    "\n",
    "def generate_random_seqs(data, column='sequence', n_seqs=1000):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        data: Dataframe that contains sequences\n",
    "        column: a name of the column which contains sequences\n",
    "\n",
    "    Returns:\n",
    "        Randomly generated sequences based on frequency of each element\n",
    "\n",
    "    \"\"\"\n",
    "    results = Counter(data[column].str.cat())\n",
    "    counts = [i[1] for i in sorted(results.items())]\n",
    "    prop = np.asarray(counts) / sum(list(counts))\n",
    "    lengths = data.sequence.str.len().sample(n_seqs).values + int(np.random.normal(scale=3))\n",
    "    seqs = []\n",
    "    for i in range(n_seqs):\n",
    "        r = np.random.choice(np.arange(1, 21), p=prop, size=lengths[i])\n",
    "        seq = \">R_{}\\nM\".format(i)\n",
    "        for a in r:\n",
    "            seq = seq + ID_TO_AMINO_ACID[a]\n",
    "        seqs.append(seq)\n",
    "    return seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_pandas(path, separator=\";\"):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        path: of the fasta file\n",
    "        separator: used in title of fasta file entry\n",
    "\n",
    "    Returns: pandas dataframe with 3 columns (id, title, sequence)\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path) as fasta_file:\n",
    "        identifiers, sequences, titles, labels = [], [], [],[]\n",
    "        id =0\n",
    "        for title, sequence in SimpleFastaParser(fasta_file):\n",
    "            title_parts = title.split(separator, 1)\n",
    "            identifiers.append(id)  # First word is ID\n",
    "            titles.append(\"1.1.1.37_\" + str(id))\n",
    "            sequences.append(sequence)\n",
    "            labels.append(\"labelx\")\n",
    "            id +=1\n",
    "        return pd.DataFrame({\"id\": identifiers, \"title\": titles,\"Label\":labels, \"sequence\": sequences})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/mohre/B/d/Research/templates/ProteinGAN/src/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fasta_to_pandas(\"./1.fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "\n",
    "output_handle1 = open(\"./train.fasta\", \"a\")\n",
    "\n",
    "for index , row in df.iterrows():\n",
    "    record = SeqRecord(\n",
    "    Seq(row['sequence']),\n",
    "    id=str(row['title']),\n",
    "    # id=str(0),\n",
    "\n",
    "    name= '',\n",
    "    description=row['title'],\n",
    "    )\n",
    "    SeqIO.write(record, output_handle1, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>Label</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_0</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[1, 18, 6, 13, 18, 1, 3, 12, 17, 8, 17, 3, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_1</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[11, 12, 10, 4, 9, 5, 18, 3, 4, 10, 13, 8, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_2</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[11, 16, 5, 16, 16, 10, 15, 15, 1, 10, 18, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_3</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[11, 3, 15, 9, 6, 8, 18, 10, 6, 16, 9, 10, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_4</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[13, 6, 13, 17, 10, 20, 1, 3, 19, 6, 3, 11, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_1146</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[16, 16, 11, 10, 9, 17, 17, 16, 8, 7, 19, 7, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_1147</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[5, 19, 20, 7, 16, 7, 10, 16, 17, 14, 20, 2, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_1148</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[8, 7, 19, 7, 6, 5, 5, 14, 9, 6, 16, 16, 19, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_1149</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[7, 19, 7, 6, 5, 5, 14, 1, 6, 17, 12, 19, 1, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.37_1150</td>\n",
       "      <td>labelx</td>\n",
       "      <td>[1, 8, 6, 13, 18, 17, 12, 10, 17, 8, 16, 12, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1151 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          title   Label  \\\n",
       "0      0     1.1.1.37_0  labelx   \n",
       "1      0     1.1.1.37_1  labelx   \n",
       "2      0     1.1.1.37_2  labelx   \n",
       "3      0     1.1.1.37_3  labelx   \n",
       "4      0     1.1.1.37_4  labelx   \n",
       "...   ..            ...     ...   \n",
       "1146   0  1.1.1.37_1146  labelx   \n",
       "1147   0  1.1.1.37_1147  labelx   \n",
       "1148   0  1.1.1.37_1148  labelx   \n",
       "1149   0  1.1.1.37_1149  labelx   \n",
       "1150   0  1.1.1.37_1150  labelx   \n",
       "\n",
       "                                               sequence  \n",
       "0     [1, 18, 6, 13, 18, 1, 3, 12, 17, 8, 17, 3, 1, ...  \n",
       "1     [11, 12, 10, 4, 9, 5, 18, 3, 4, 10, 13, 8, 13,...  \n",
       "2     [11, 16, 5, 16, 16, 10, 15, 15, 1, 10, 18, 5, ...  \n",
       "3     [11, 3, 15, 9, 6, 8, 18, 10, 6, 16, 9, 10, 1, ...  \n",
       "4     [13, 6, 13, 17, 10, 20, 1, 3, 19, 6, 3, 11, 8,...  \n",
       "...                                                 ...  \n",
       "1146  [16, 16, 11, 10, 9, 17, 17, 16, 8, 7, 19, 7, 6...  \n",
       "1147  [5, 19, 20, 7, 16, 7, 10, 16, 17, 14, 20, 2, 3...  \n",
       "1148  [8, 7, 19, 7, 6, 5, 5, 14, 9, 6, 16, 16, 19, 1...  \n",
       "1149  [7, 19, 7, 6, 5, 5, 14, 1, 6, 17, 12, 19, 1, 3...  \n",
       "1150  [1, 8, 6, 13, 18, 17, 12, 10, 17, 8, 16, 12, 1...  \n",
       "\n",
       "[1151 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fasta_to_pandas(\"./train.fasta\")\n",
    "\n",
    "df[\"sequence\"] = from_amino_acid_to_id(df , \"sequence\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was stored in ./labelx.tfrecords\n",
      "Completed all threads in 1.0038206577301025 seconds\n"
     ]
    }
   ],
   "source": [
    "def save_as_tfrecords_multithreaded(path, original_data, columns=[\"sequence\"], group_by_col=\"Label\"):\n",
    "    \"\"\"Provided data gets splitted in to groups and processed concurrently.\n",
    "    The outcome of this is a file per group.\n",
    "\n",
    "    Args:\n",
    "      path: Location where files should be stored\n",
    "      original_data: dataframe which should be converted into files\n",
    "      columns: a  list of columns which should be stored as sequences (Default value = [\"sequence\"])\n",
    "      group_by_col: a column name by which split data into groups (Default value = \"Label\")\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    threading_start = time.time()\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = []\n",
    "    data = original_data.groupby(group_by_col)\n",
    "    for group_id in data.groups:\n",
    "        if isinstance(group_id, str):\n",
    "            group_name = group_id.replace(\".\", \"_\").replace(\"-\", \"_\")\n",
    "        elif isinstance(group_id, int):\n",
    "            group_name = str(group_id)\n",
    "        else:\n",
    "            group_name = \"_\".join([str(e) for e in group_id])\n",
    "        filename = os.path.join(path, group_name)\n",
    "        args = (filename, data.get_group(group_id), columns)\n",
    "        t = threading.Thread(target=save_as_tfrecords, args=args)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    coord.join(threads)\n",
    "    print(\"Completed all threads in {} seconds\".format(time.time() - threading_start))\n",
    "\n",
    "\n",
    "def save_as_tfrecords(filename, data, columns=[\"sequence\"], extension=\"tfrecords\"):\n",
    "    \"\"\"Processes a dataframe and stores data into tfrecord file\n",
    "\n",
    "    Args:\n",
    "      filename: the absolute path of the tfrecords file where data should be stored\n",
    "      data: dataframe containing data will be converted into tfrecord\n",
    "      columns: list of columns that should be stored as varying-length sequences (Default value = [\"sequence\"])\n",
    "      extension: file extension\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        filename = \"{}.{}\".format(filename, extension)\n",
    "        with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "            for index, row in data.iterrows():\n",
    "                feature = {\n",
    "                    'label': to_int_feature([row[0]])\n",
    "                }\n",
    "                for col_name in columns:\n",
    "                    value = row[col_name]\n",
    "                    if isinstance(value, int):\n",
    "                        feature[col_name] = to_int_feature([value])\n",
    "                    elif isinstance(value, float):\n",
    "                        feature[col_name] = to_float_feature([value])\n",
    "                    elif not isinstance(value, (list,)) and not (isinstance (value, int) or ((value.dtype == np.float32) or (value.dtype == np.float64))):\n",
    "                        feature[col_name] = to_float_feature(value)\n",
    "                    else:\n",
    "                        feature[col_name] = to_int_feature(value)\n",
    "                        feature['length_' + col_name] = to_int_feature([len(value)])\n",
    "                print(feature)\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example.SerializeToString())\n",
    "\n",
    "        print(\"Data was stored in {}\".format(filename))\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong went writting in to tfrecords file\")\n",
    "        print(\"Error is \", str(e))\n",
    "save_as_tfrecords_multithreaded(\".\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val_sequences.fasta'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "os.makedirs('train', exist_ok=True)\n",
    "os.makedirs('val', exist_ok=True)\n",
    "shutil.copy('labelx.tfrecords', 'train/')\n",
    "shutil.copy('labelx.tfrecords', 'val/')\n",
    "\n",
    "shutil.copy('train.fasta', 'train_sequences.fasta')\n",
    "shutil.copy('train.fasta', 'val_sequences.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USAGE\n",
      "  makeblastdb [-h] [-help] [-in input_file] [-input_type type]\n",
      "    -dbtype molecule_type [-title database_title] [-parse_seqids]\n",
      "    [-hash_index] [-mask_data mask_data_files] [-mask_id mask_algo_ids]\n",
      "    [-mask_desc mask_algo_descriptions] [-gi_mask]\n",
      "    [-gi_mask_name gi_based_mask_names] [-out database_name]\n",
      "    [-max_file_sz number_of_bytes] [-logfile File_Name] [-taxid TaxID]\n",
      "    [-taxid_map TaxIDMapFile] [-version]\n",
      "\n",
      "DESCRIPTION\n",
      "   Application to create BLAST databases, version 2.5.0+\n",
      "\n",
      "Use '-help' to print detailed descriptions of command line arguments\n",
      "========================================================================\n",
      "\n",
      "Error: Unknown argument: \"blastdb_version\"\n",
      "Error:  (CArgException::eInvalidArg) Unknown argument: \"blastdb_version\"\n"
     ]
    }
   ],
   "source": [
    "! makeblastdb -in train_sequences.fasta -out db_train  -parse_seqids -blastdb_version 5  -title \"train sequence\" -dbtype prot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mohre/B/d/Research/templates/ProteinGAN/data/protein/x'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree('/home/mohre/B/d/Research/templates/ProteinGAN/src/a','/home/mohre/B/d/Research/templates/ProteinGAN/data/protein/x')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f75712e99c1c6a9086d73d4ce09ed54b054c9611445d87dbde64d2fd43231787"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf1.14': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
